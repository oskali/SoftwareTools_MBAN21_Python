{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "We'll take a tour of the methods for classification in sklearn. First let's load a toy dataset to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert it to a dataframe for better visuals\n",
    "df = pd.DataFrame(breast.data)\n",
    "df.columns = breast.feature_names\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now look at the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(breast.target_names)\n",
    "breast.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the scikit learn models is basically the same as in Julia's ScikitLearn.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, min_samples_leaf=140)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "cart = DecisionTreeClassifier(max_depth=2, min_samples_leaf=140)\n",
    "cart.fit(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helper function to plot the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Graphviz (tedious)\n",
    "\n",
    "## Windows\n",
    "\n",
    "1. Download graphviz from https://graphviz.gitlab.io/_pages/Download/Download_windows.html\n",
    "2. Install it by running the .msi file\n",
    "3. Set the pat variable:\n",
    "    (a) Go to Control Panel > System and Security > System > Advanced System Settings >  Environment Variables > Path > Edit\n",
    "    (b) Add 'C:\\Program Files (x86)\\Graphviz2.38\\bin'\n",
    "4. Run `conda install graphviz`\n",
    "5. Run `conda install python-graphviz`\n",
    "\n",
    "## macOS and Linux\n",
    "\n",
    "1. Run `brew install graphviz` (install `brew` from https://docs.brew.sh/Installation if you don't have it)\n",
    "2. Run `conda install graphviz`\n",
    "3. Run `conda install python-graphviz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import sklearn.tree\n",
    "def visualize_tree(sktree):\n",
    "    dot_data = sklearn.tree.export_graphviz(sktree, out_file=None, \n",
    "                                    filled=True, rounded=True,  \n",
    "                                    special_characters=False,\n",
    "                                    feature_names=df.columns)\n",
    "    return graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"378pt\" height=\"269pt\"\r\n",
       " viewBox=\"0.00 0.00 377.50 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-265 373.5,-265 373.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#afd7f4\" stroke=\"black\" d=\"M285,-261C285,-261 148,-261 148,-261 142,-261 136,-255 136,-249 136,-249 136,-205 136,-205 136,-199 142,-193 148,-193 148,-193 285,-193 285,-193 291,-193 297,-199 297,-205 297,-205 297,-249 297,-249 297,-255 291,-261 285,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst radius &lt;= 16.795</text>\r\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.468</text>\r\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 569</text>\r\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [212, 357]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#4ca6e7\" stroke=\"black\" d=\"M217.5,-157C217.5,-157 31.5,-157 31.5,-157 25.5,-157 19.5,-151 19.5,-145 19.5,-145 19.5,-101 19.5,-101 19.5,-95 25.5,-89 31.5,-89 31.5,-89 217.5,-89 217.5,-89 223.5,-89 229.5,-95 229.5,-101 229.5,-101 229.5,-145 229.5,-145 229.5,-151 223.5,-157 217.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"124.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst concave points &lt;= 0.087</text>\r\n",
       "<text text-anchor=\"middle\" x=\"124.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.159</text>\r\n",
       "<text text-anchor=\"middle\" x=\"124.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 379</text>\r\n",
       "<text text-anchor=\"middle\" x=\"124.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [33, 346]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M186.63,-192.884C178.596,-183.976 169.81,-174.235 161.441,-164.957\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"163.831,-162.381 154.535,-157.299 158.633,-167.069 163.831,-162.381\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"153.248\" y=\"-178.566\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#e78945\" stroke=\"black\" d=\"M357.5,-149.5C357.5,-149.5 259.5,-149.5 259.5,-149.5 253.5,-149.5 247.5,-143.5 247.5,-137.5 247.5,-137.5 247.5,-108.5 247.5,-108.5 247.5,-102.5 253.5,-96.5 259.5,-96.5 259.5,-96.5 357.5,-96.5 357.5,-96.5 363.5,-96.5 369.5,-102.5 369.5,-108.5 369.5,-108.5 369.5,-137.5 369.5,-137.5 369.5,-143.5 363.5,-149.5 357.5,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"308.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.109</text>\r\n",
       "<text text-anchor=\"middle\" x=\"308.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 190</text>\r\n",
       "<text text-anchor=\"middle\" x=\"308.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [179, 11]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>0&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M246.37,-192.884C256.686,-181.446 268.242,-168.634 278.564,-157.19\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"281.383,-159.29 285.482,-149.52 276.185,-154.601 281.383,-159.29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"286.769\" y=\"-170.787\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#3b9ee5\" stroke=\"black\" d=\"M101,-53C101,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 101,-0 101,-0 107,-0 113,-6 113,-12 113,-12 113,-41 113,-41 113,-47 107,-53 101,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.017</text>\r\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 239</text>\r\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 237]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M100.717,-88.9485C94.3317,-80.0749 87.4165,-70.4648 80.9935,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.7013,-59.3094 75.0195,-53.2367 78.0194,-63.398 83.7013,-59.3094\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#71b9ec\" stroke=\"black\" d=\"M241.5,-53C241.5,-53 143.5,-53 143.5,-53 137.5,-53 131.5,-47 131.5,-41 131.5,-41 131.5,-12 131.5,-12 131.5,-6 137.5,-0 143.5,-0 143.5,-0 241.5,-0 241.5,-0 247.5,-0 253.5,-6 253.5,-12 253.5,-12 253.5,-41 253.5,-41 253.5,-47 247.5,-53 241.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"192.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.345</text>\r\n",
       "<text text-anchor=\"middle\" x=\"192.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 140</text>\r\n",
       "<text text-anchor=\"middle\" x=\"192.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 109]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.283,-88.9485C154.668,-80.0749 161.584,-70.4648 168.007,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.981,-63.398 173.98,-53.2367 165.299,-59.3094 170.981,-63.398\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x17b509eae80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_tree(cart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can get the label predictions with the `.predict` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = cart.predict(breast.data)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarly the predicted probabilities with `.predict_proba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94210526, 0.05789474],\n",
       "       [0.94210526, 0.05789474],\n",
       "       [0.94210526, 0.05789474],\n",
       "       ...,\n",
       "       [0.94210526, 0.05789474],\n",
       "       [0.94210526, 0.05789474],\n",
       "       [0.0083682 , 0.9916318 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = cart.predict_proba(breast.data)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in Julia, the probabilities are returned for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the second column of the probs by slicing, just like how we did it in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05789474, 0.05789474, 0.05789474, 0.77857143, 0.05789474,\n",
       "       0.77857143, 0.05789474, 0.05789474, 0.77857143, 0.77857143,\n",
       "       0.05789474, 0.05789474, 0.05789474, 0.05789474, 0.77857143,\n",
       "       0.05789474, 0.05789474, 0.05789474, 0.05789474, 0.77857143,\n",
       "       0.9916318 , 0.9916318 , 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.05789474, 0.05789474, 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.05789474, 0.05789474, 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.05789474, 0.77857143, 0.9916318 , 0.9916318 , 0.77857143,\n",
       "       0.77857143, 0.77857143, 0.05789474, 0.05789474, 0.77857143,\n",
       "       0.05789474, 0.9916318 , 0.77857143, 0.9916318 , 0.77857143,\n",
       "       0.9916318 , 0.9916318 , 0.9916318 , 0.05789474, 0.05789474,\n",
       "       0.9916318 , 0.05789474, 0.05789474, 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.05789474, 0.9916318 , 0.05789474,\n",
       "       0.05789474, 0.9916318 , 0.9916318 , 0.77857143, 0.9916318 ,\n",
       "       0.05789474, 0.9916318 , 0.05789474, 0.77857143, 0.9916318 ,\n",
       "       0.05789474, 0.9916318 , 0.05789474, 0.05789474, 0.9916318 ,\n",
       "       0.9916318 , 0.77857143, 0.05789474, 0.05789474, 0.9916318 ,\n",
       "       0.05789474, 0.77857143, 0.05789474, 0.77857143, 0.77857143,\n",
       "       0.9916318 , 0.77857143, 0.77857143, 0.9916318 , 0.05789474,\n",
       "       0.05789474, 0.9916318 , 0.9916318 , 0.9916318 , 0.77857143,\n",
       "       0.05789474, 0.9916318 , 0.9916318 , 0.77857143, 0.9916318 ,\n",
       "       0.77857143, 0.77857143, 0.9916318 , 0.05789474, 0.9916318 ,\n",
       "       0.9916318 , 0.77857143, 0.77857143, 0.9916318 , 0.77857143,\n",
       "       0.9916318 , 0.9916318 , 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.77857143, 0.05789474, 0.05789474, 0.77857143, 0.77857143,\n",
       "       0.9916318 , 0.05789474, 0.05789474, 0.77857143, 0.05789474,\n",
       "       0.9916318 , 0.05789474, 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.77857143, 0.9916318 , 0.9916318 , 0.05789474, 0.9916318 ,\n",
       "       0.9916318 , 0.05789474, 0.9916318 , 0.77857143, 0.9916318 ,\n",
       "       0.9916318 , 0.77857143, 0.9916318 , 0.77857143, 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.77857143, 0.9916318 , 0.77857143,\n",
       "       0.9916318 , 0.05789474, 0.05789474, 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.05789474, 0.05789474, 0.9916318 , 0.05789474,\n",
       "       0.9916318 , 0.9916318 , 0.05789474, 0.05789474, 0.9916318 ,\n",
       "       0.77857143, 0.05789474, 0.05789474, 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.77857143, 0.05789474, 0.9916318 , 0.9916318 ,\n",
       "       0.05789474, 0.05789474, 0.05789474, 0.9916318 , 0.05789474,\n",
       "       0.9916318 , 0.05789474, 0.77857143, 0.9916318 , 0.9916318 ,\n",
       "       0.77857143, 0.9916318 , 0.9916318 , 0.77857143, 0.77857143,\n",
       "       0.9916318 , 0.77857143, 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.77857143, 0.05789474, 0.05789474, 0.05789474, 0.77857143,\n",
       "       0.05789474, 0.9916318 , 0.05789474, 0.77857143, 0.05789474,\n",
       "       0.05789474, 0.9916318 , 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.77857143, 0.77857143, 0.9916318 , 0.05789474, 0.05789474,\n",
       "       0.9916318 , 0.77857143, 0.9916318 , 0.05789474, 0.77857143,\n",
       "       0.77857143, 0.9916318 , 0.77857143, 0.77857143, 0.77857143,\n",
       "       0.05789474, 0.9916318 , 0.9916318 , 0.05789474, 0.9916318 ,\n",
       "       0.9916318 , 0.05789474, 0.05789474, 0.9916318 , 0.05789474,\n",
       "       0.77857143, 0.9916318 , 0.77857143, 0.9916318 , 0.05789474,\n",
       "       0.9916318 , 0.9916318 , 0.77857143, 0.9916318 , 0.77857143,\n",
       "       0.05789474, 0.9916318 , 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.77857143, 0.05789474, 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.05789474, 0.05789474, 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.05789474, 0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.77857143, 0.05789474, 0.9916318 , 0.05789474,\n",
       "       0.77857143, 0.9916318 , 0.05789474, 0.9916318 , 0.77857143,\n",
       "       0.05789474, 0.9916318 , 0.05789474, 0.05789474, 0.77857143,\n",
       "       0.9916318 , 0.77857143, 0.9916318 , 0.77857143, 0.9916318 ,\n",
       "       0.77857143, 0.77857143, 0.77857143, 0.77857143, 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.05789474, 0.9916318 , 0.05789474, 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.05789474, 0.77857143, 0.9916318 ,\n",
       "       0.77857143, 0.05789474, 0.77857143, 0.05789474, 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.9916318 , 0.05789474, 0.05789474,\n",
       "       0.05789474, 0.77857143, 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.05789474, 0.9916318 , 0.05789474, 0.9916318 , 0.05789474,\n",
       "       0.77857143, 0.9916318 , 0.77857143, 0.05789474, 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.05789474, 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.05789474, 0.05789474, 0.05789474, 0.9916318 ,\n",
       "       0.77857143, 0.77857143, 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.9916318 , 0.05789474, 0.9916318 ,\n",
       "       0.05789474, 0.05789474, 0.77857143, 0.05789474, 0.05789474,\n",
       "       0.05789474, 0.9916318 , 0.05789474, 0.05789474, 0.9916318 ,\n",
       "       0.05789474, 0.77857143, 0.9916318 , 0.77857143, 0.77857143,\n",
       "       0.77857143, 0.9916318 , 0.77857143, 0.77857143, 0.77857143,\n",
       "       0.77857143, 0.77857143, 0.9916318 , 0.9916318 , 0.05789474,\n",
       "       0.9916318 , 0.9916318 , 0.05789474, 0.05789474, 0.9916318 ,\n",
       "       0.9916318 , 0.77857143, 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.05789474, 0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.05789474, 0.9916318 , 0.05789474, 0.77857143,\n",
       "       0.9916318 , 0.9916318 , 0.9916318 , 0.77857143, 0.05789474,\n",
       "       0.9916318 , 0.9916318 , 0.05789474, 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.77857143, 0.77857143, 0.77857143, 0.9916318 ,\n",
       "       0.9916318 , 0.77857143, 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.77857143, 0.9916318 , 0.05789474, 0.05789474, 0.9916318 ,\n",
       "       0.05789474, 0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.77857143, 0.05789474, 0.9916318 , 0.9916318 , 0.05789474,\n",
       "       0.77857143, 0.05789474, 0.9916318 , 0.77857143, 0.05789474,\n",
       "       0.77857143, 0.05789474, 0.9916318 , 0.77857143, 0.77857143,\n",
       "       0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.05789474, 0.05789474, 0.9916318 , 0.9916318 , 0.77857143,\n",
       "       0.77857143, 0.77857143, 0.9916318 , 0.05789474, 0.77857143,\n",
       "       0.9916318 , 0.9916318 , 0.05789474, 0.9916318 , 0.9916318 ,\n",
       "       0.77857143, 0.77857143, 0.9916318 , 0.9916318 , 0.05789474,\n",
       "       0.9916318 , 0.9916318 , 0.77857143, 0.77857143, 0.05789474,\n",
       "       0.77857143, 0.9916318 , 0.05789474, 0.77857143, 0.05789474,\n",
       "       0.9916318 , 0.05789474, 0.05789474, 0.9916318 , 0.9916318 ,\n",
       "       0.77857143, 0.77857143, 0.77857143, 0.05789474, 0.05789474,\n",
       "       0.77857143, 0.77857143, 0.9916318 , 0.05789474, 0.77857143,\n",
       "       0.77857143, 0.9916318 , 0.77857143, 0.05789474, 0.05789474,\n",
       "       0.77857143, 0.9916318 , 0.77857143, 0.77857143, 0.05789474,\n",
       "       0.9916318 , 0.05789474, 0.05789474, 0.77857143, 0.9916318 ,\n",
       "       0.9916318 , 0.05789474, 0.9916318 , 0.77857143, 0.9916318 ,\n",
       "       0.9916318 , 0.77857143, 0.77857143, 0.77857143, 0.9916318 ,\n",
       "       0.77857143, 0.9916318 , 0.77857143, 0.05789474, 0.77857143,\n",
       "       0.05789474, 0.77857143, 0.77857143, 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.77857143, 0.77857143, 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 , 0.9916318 ,\n",
       "       0.77857143, 0.9916318 , 0.9916318 , 0.77857143, 0.77857143,\n",
       "       0.77857143, 0.9916318 , 0.05789474, 0.05789474, 0.05789474,\n",
       "       0.05789474, 0.05789474, 0.05789474, 0.9916318 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = cart.predict_proba(breast.data)[:,1]\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, we can use functions from `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538607895988584"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(breast.target, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9226713532513181"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(breast.target, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[179,  33],\n",
       "       [ 11, 346]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omars\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03<00:00,  8.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheckingClassifier</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "LinearSVC                          0.99               0.99     0.99      0.99   \n",
       "Perceptron                         0.99               0.98     0.98      0.99   \n",
       "LogisticRegression                 0.99               0.98     0.98      0.99   \n",
       "SVC                                0.98               0.98     0.98      0.98   \n",
       "XGBClassifier                      0.98               0.98     0.98      0.98   \n",
       "LabelPropagation                   0.98               0.97     0.97      0.98   \n",
       "LabelSpreading                     0.98               0.97     0.97      0.98   \n",
       "BaggingClassifier                  0.97               0.97     0.97      0.97   \n",
       "PassiveAggressiveClassifier        0.98               0.97     0.97      0.98   \n",
       "SGDClassifier                      0.98               0.97     0.97      0.98   \n",
       "RandomForestClassifier             0.97               0.97     0.97      0.97   \n",
       "CalibratedClassifierCV             0.98               0.97     0.97      0.98   \n",
       "QuadraticDiscriminantAnalysis      0.96               0.97     0.97      0.97   \n",
       "ExtraTreesClassifier               0.97               0.96     0.96      0.97   \n",
       "RidgeClassifierCV                  0.97               0.96     0.96      0.97   \n",
       "LGBMClassifier                     0.96               0.96     0.96      0.96   \n",
       "RidgeClassifier                    0.97               0.96     0.96      0.97   \n",
       "AdaBoostClassifier                 0.96               0.96     0.96      0.96   \n",
       "KNeighborsClassifier               0.96               0.96     0.96      0.96   \n",
       "BernoulliNB                        0.95               0.95     0.95      0.95   \n",
       "LinearDiscriminantAnalysis         0.96               0.95     0.95      0.96   \n",
       "GaussianNB                         0.95               0.95     0.95      0.95   \n",
       "NuSVC                              0.95               0.94     0.94      0.95   \n",
       "ExtraTreeClassifier                0.94               0.93     0.93      0.94   \n",
       "NearestCentroid                    0.95               0.93     0.93      0.95   \n",
       "DecisionTreeClassifier             0.93               0.93     0.93      0.93   \n",
       "CheckingClassifier                 0.36               0.50     0.50      0.19   \n",
       "DummyClassifier                    0.53               0.50     0.50      0.53   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "LinearSVC                            0.05  \n",
       "Perceptron                           0.02  \n",
       "LogisticRegression                   0.13  \n",
       "SVC                                  0.03  \n",
       "XGBClassifier                        0.11  \n",
       "LabelPropagation                     0.03  \n",
       "LabelSpreading                       0.05  \n",
       "BaggingClassifier                    0.10  \n",
       "PassiveAggressiveClassifier          0.07  \n",
       "SGDClassifier                        0.03  \n",
       "RandomForestClassifier               0.38  \n",
       "CalibratedClassifierCV               0.10  \n",
       "QuadraticDiscriminantAnalysis        0.52  \n",
       "ExtraTreesClassifier                 0.21  \n",
       "RidgeClassifierCV                    0.05  \n",
       "LGBMClassifier                       0.20  \n",
       "RidgeClassifier                      0.17  \n",
       "AdaBoostClassifier                   0.33  \n",
       "KNeighborsClassifier                 0.21  \n",
       "BernoulliNB                          0.05  \n",
       "LinearDiscriminantAnalysis           0.13  \n",
       "GaussianNB                           0.01  \n",
       "NuSVC                                0.06  \n",
       "ExtraTreeClassifier                  0.04  \n",
       "NearestCentroid                      0.05  \n",
       "DecisionTreeClassifier               0.08  \n",
       "CheckingClassifier                   0.04  \n",
       "DummyClassifier                      0.06  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y= data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.5,random_state =123)\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests and Boosting\n",
    "\n",
    "We use random forests and boosting in the same way as CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[212,   0],\n",
       "       [  0, 357]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = forest.predict(breast.data)\n",
    "probs = forest.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "boost = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1)\n",
    "boost.fit(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[212,   0],\n",
       "       [  0, 357]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = boost.predict(breast.data)\n",
    "probs = boost.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "boost2 = XGBClassifier()\n",
    "boost2.fit(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[212,   0],\n",
       "       [  0, 357]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = boost2.predict(breast.data)\n",
    "probs = boost2.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "mlp.fit(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993235029861001\n",
      "0.9490333919156415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[187,  25],\n",
       "       [  4, 353]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = mlp.predict(breast.data)\n",
    "probs = mlp.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 36.4088 - accuracy: 0.3516\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 17.8082 - accuracy: 0.3758\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 15.4570 - accuracy: 0.4352\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 12.8511 - accuracy: 0.4769\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 10.6894 - accuracy: 0.5319\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 9.3079 - accuracy: 0.5670\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 8.3241 - accuracy: 0.5824\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.3370 - accuracy: 0.6264\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.6161 - accuracy: 0.6154\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.6886 - accuracy: 0.6374\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.7604 - accuracy: 0.6491\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 25.0130 - accuracy: 0.4593\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 9.2743 - accuracy: 0.2923\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.6822 - accuracy: 0.3385\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.5664 - accuracy: 0.4198\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.2452 - accuracy: 0.5253\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.2986 - accuracy: 0.6000\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.7611 - accuracy: 0.6923\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.3770 - accuracy: 0.7231\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.2754 - accuracy: 0.7407\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.1074 - accuracy: 0.7912\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8304 - accuracy: 0.7544\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 19.6493 - accuracy: 0.5560\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.1954 - accuracy: 0.9033\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.7177 - accuracy: 0.8593\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5284 - accuracy: 0.8901\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.5605 - accuracy: 0.9033\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.4026 - accuracy: 0.8901\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.3803 - accuracy: 0.8923: 0s - loss: 1.4837 - accuracy: 0.89\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.2817 - accuracy: 0.9011\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.4488 - accuracy: 0.8835\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.2524 - accuracy: 0.8923\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.6985 - accuracy: 0.8684\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 69.7143 - accuracy: 0.3714\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 25.4033 - accuracy: 0.3912\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.2258 - accuracy: 0.8725\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.8741 - accuracy: 0.8637\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.7284 - accuracy: 0.8813\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.7166 - accuracy: 0.8747\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.6775 - accuracy: 0.8923\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.6431 - accuracy: 0.8923\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.6271 - accuracy: 0.8703\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.5868 - accuracy: 0.8879\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1058 - accuracy: 0.8684\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 9.9503 - accuracy: 0.3838\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 6.8765 - accuracy: 0.3816\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.1510 - accuracy: 0.4561\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.8095 - accuracy: 0.5592\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.1159 - accuracy: 0.6623\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6108 - accuracy: 0.6820\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.1609 - accuracy: 0.7259\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.9964 - accuracy: 0.7456\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.7422 - accuracy: 0.7763\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.6857 - accuracy: 0.7500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4334 - accuracy: 0.8319\n",
      "Baseline: 79.44% (8.37%)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "X = breast.data\n",
    "Y = breast.target\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(Y)\n",
    " \n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=30, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=10, batch_size=16, verbose=1)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We can also access logistic regression from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(solver='liblinear')\n",
    "logit.fit(breast.data, breast.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9945298874266688\n",
      "0.9578207381370826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[197,  15],\n",
       "       [  9, 348]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = logit.predict(breast.data)\n",
    "probs = logit.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn implementation has options for regularization in logistic regression. You can choose between L1 and L2 regularization:\n",
    "\n",
    "![](http://scikit-learn.org/stable/_images/math/6a0bcf21baaeb0c2b879ab74fe333c0aab0d6ae6.png)\n",
    "\n",
    "\n",
    "![](http://scikit-learn.org/stable/_images/math/760c999ccbc78b72d2a91186ba55ce37f0d2cf37.png)\n",
    "\n",
    "Note that this regularization is adhoc and **not equivalent to robustness**. For a robust logistic regression, follow the approach from 15.680.\n",
    "\n",
    "You control the regularization with the `penalty` and `C` hyperparameters. We can see that our model above used L2 regularization with $C=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try out unregularized logistic regression as well as L1 regularization. Which of the three options seems best? What if you try changing $C$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996789281750436\n",
      "0.9718804920913884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[202,  10],\n",
       "       [  6, 351]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No regularization\n",
    "logit = LogisticRegression(C=1e10, solver='liblinear')\n",
    "logit.fit(breast.data, breast.target)\n",
    "labels = logit.predict(breast.data)\n",
    "probs = logit.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985201627820939\n",
      "0.9876977152899824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[207,   5],\n",
       "       [  2, 355]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 regularization\n",
    "logit = LogisticRegression(C=100, penalty='l1', solver='liblinear')\n",
    "logit.fit(breast.data, breast.target)\n",
    "labels = logit.predict(breast.data)\n",
    "probs = logit.predict_proba(breast.data)[:,1]\n",
    "print(roc_auc_score(breast.target, probs))\n",
    "print(accuracy_score(breast.target, labels))\n",
    "confusion_matrix(breast.target, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "Now let's take a look at regression in sklearn. Again we can start by loading up a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(boston.data)\n",
    "df.columns = boston.feature_names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Trees\n",
    "\n",
    "We use regression trees in the same way as classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"506pt\" height=\"269pt\"\r\n",
       " viewBox=\"0.00 0.00 505.50 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-265 501.5,-265 501.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#f8dfcd\" stroke=\"black\" d=\"M292,-261C292,-261 205,-261 205,-261 199,-261 193,-255 193,-249 193,-249 193,-205 193,-205 193,-199 199,-193 205,-193 205,-193 292,-193 292,-193 298,-193 304,-199 304,-205 304,-205 304,-249 304,-249 304,-255 298,-261 292,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RM &lt;= 6.941</text>\r\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 84.42</text>\r\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 506</text>\r\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 22.533</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#fbeade\" stroke=\"black\" d=\"M229,-157C229,-157 138,-157 138,-157 132,-157 126,-151 126,-145 126,-145 126,-101 126,-101 126,-95 132,-89 138,-89 138,-89 229,-89 229,-89 235,-89 241,-95 241,-101 241,-101 241,-145 241,-145 241,-151 235,-157 229,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">LSTAT &lt;= 14.4</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 40.273</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 430</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 19.934</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.396,-192.884C221.89,-184.243 215.885,-174.819 210.133,-165.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"213.046,-163.852 204.72,-157.299 207.143,-167.614 213.046,-163.852\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"199.312\" y=\"-178.007\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#eca26d\" stroke=\"black\" d=\"M357.5,-157C357.5,-157 271.5,-157 271.5,-157 265.5,-157 259.5,-151 259.5,-145 259.5,-145 259.5,-101 259.5,-101 259.5,-95 265.5,-89 271.5,-89 271.5,-89 357.5,-89 357.5,-89 363.5,-89 369.5,-95 369.5,-101 369.5,-101 369.5,-145 369.5,-145 369.5,-151 363.5,-157 357.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"314.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">RM &lt;= 7.437</text>\r\n",
       "<text text-anchor=\"middle\" x=\"314.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 79.729</text>\r\n",
       "<text text-anchor=\"middle\" x=\"314.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 76</text>\r\n",
       "<text text-anchor=\"middle\" x=\"314.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 37.238</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>0&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M269.928,-192.884C275.519,-184.243 281.617,-174.819 287.458,-165.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"290.459,-167.596 292.953,-157.299 284.582,-163.794 290.459,-167.596\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"298.192\" y=\"-178.044\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#f8dcc8\" stroke=\"black\" d=\"M99,-53C99,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 99,-0 99,-0 105,-0 111,-6 111,-12 111,-12 111,-41 111,-41 111,-47 105,-53 99,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"55.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 26.009</text>\r\n",
       "<text text-anchor=\"middle\" x=\"55.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 255</text>\r\n",
       "<text text-anchor=\"middle\" x=\"55.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 23.35</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M138.732,-88.9485C125.721,-79.3431 111.542,-68.8747 98.634,-59.345\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.484,-56.3605 90.3603,-53.2367 96.3265,-61.992 100.484,-56.3605\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M228,-53C228,-53 141,-53 141,-53 135,-53 129,-47 129,-41 129,-41 129,-12 129,-12 129,-6 135,-0 141,-0 141,-0 228,-0 228,-0 234,-0 240,-6 240,-12 240,-12 240,-41 240,-41 240,-47 234,-53 228,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"184.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 19.276</text>\r\n",
       "<text text-anchor=\"middle\" x=\"184.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 175</text>\r\n",
       "<text text-anchor=\"middle\" x=\"184.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 14.956</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M183.85,-88.9485C183.937,-80.7153 184.031,-71.848 184.119,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"187.622,-63.2732 184.228,-53.2367 180.622,-63.1991 187.622,-63.2732\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#f0b78e\" stroke=\"black\" d=\"M357.5,-53C357.5,-53 271.5,-53 271.5,-53 265.5,-53 259.5,-47 259.5,-41 259.5,-41 259.5,-12 259.5,-12 259.5,-6 265.5,-0 271.5,-0 271.5,-0 357.5,-0 357.5,-0 363.5,-0 369.5,-6 369.5,-12 369.5,-12 369.5,-41 369.5,-41 369.5,-47 363.5,-53 357.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"314.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 41.296</text>\r\n",
       "<text text-anchor=\"middle\" x=\"314.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\r\n",
       "<text text-anchor=\"middle\" x=\"314.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 32.113</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M314.5,-88.9485C314.5,-80.7153 314.5,-71.848 314.5,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"318,-63.2367 314.5,-53.2367 311,-63.2367 318,-63.2367\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M485.5,-53C485.5,-53 399.5,-53 399.5,-53 393.5,-53 387.5,-47 387.5,-41 387.5,-41 387.5,-12 387.5,-12 387.5,-6 393.5,-0 399.5,-0 399.5,-0 485.5,-0 485.5,-0 491.5,-0 497.5,-6 497.5,-12 497.5,-12 497.5,-41 497.5,-41 497.5,-47 491.5,-53 485.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"442.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 36.628</text>\r\n",
       "<text text-anchor=\"middle\" x=\"442.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\r\n",
       "<text text-anchor=\"middle\" x=\"442.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 45.097</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.268,-88.9485C372.279,-79.3431 386.458,-68.8747 399.366,-59.345\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"401.673,-61.992 407.64,-53.2367 397.516,-56.3605 401.673,-61.992\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x17b5165fd68>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "cart = DecisionTreeRegressor(max_depth=2, min_samples_leaf=5)\n",
    "cart.fit(boston.data, boston.target)\n",
    "visualize_tree(cart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like for classification, we get the predicted labels out with the `.predict` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.34980392, 23.34980392, 32.11304348, 32.11304348, 32.11304348,\n",
       "       23.34980392, 23.34980392, 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 23.34980392, 14.956     , 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 14.956     , 23.34980392, 23.34980392,\n",
       "       14.956     , 23.34980392, 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 23.34980392, 23.34980392,\n",
       "       14.956     , 23.34980392, 14.956     , 14.956     , 14.956     ,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       32.11304348, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 14.956     , 14.956     , 14.956     ,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 14.956     ,\n",
       "       32.11304348, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 14.956     , 23.34980392, 23.34980392, 32.11304348,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 32.11304348, 32.11304348,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 45.09666667, 45.09666667, 32.11304348,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       14.956     , 14.956     , 23.34980392, 23.34980392, 14.956     ,\n",
       "       23.34980392, 23.34980392, 14.956     , 14.956     , 23.34980392,\n",
       "       14.956     , 23.34980392, 23.34980392, 14.956     , 23.34980392,\n",
       "       23.34980392, 23.34980392, 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       23.34980392, 23.34980392, 23.34980392, 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       23.34980392, 23.34980392, 23.34980392, 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 32.11304348, 23.34980392, 23.34980392,\n",
       "       23.34980392, 45.09666667, 45.09666667, 45.09666667, 23.34980392,\n",
       "       23.34980392, 45.09666667, 23.34980392, 23.34980392, 23.34980392,\n",
       "       14.956     , 23.34980392, 14.956     , 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 32.11304348,\n",
       "       45.09666667, 23.34980392, 32.11304348, 23.34980392, 23.34980392,\n",
       "       23.34980392, 45.09666667, 23.34980392, 23.34980392, 32.11304348,\n",
       "       32.11304348, 23.34980392, 32.11304348, 23.34980392, 23.34980392,\n",
       "       45.09666667, 32.11304348, 32.11304348, 32.11304348, 32.11304348,\n",
       "       32.11304348, 23.34980392, 45.09666667, 45.09666667, 45.09666667,\n",
       "       23.34980392, 23.34980392, 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 23.34980392, 14.956     ,\n",
       "       23.34980392, 23.34980392, 23.34980392, 14.956     , 23.34980392,\n",
       "       32.11304348, 14.956     , 23.34980392, 23.34980392, 45.09666667,\n",
       "       45.09666667, 45.09666667, 32.11304348, 45.09666667, 23.34980392,\n",
       "       23.34980392, 32.11304348, 45.09666667, 45.09666667, 23.34980392,\n",
       "       23.34980392, 23.34980392, 32.11304348, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       14.956     , 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 32.11304348, 45.09666667, 23.34980392,\n",
       "       23.34980392, 45.09666667, 45.09666667, 32.11304348, 23.34980392,\n",
       "       32.11304348, 45.09666667, 45.09666667, 32.11304348, 32.11304348,\n",
       "       23.34980392, 32.11304348, 45.09666667, 45.09666667, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 45.09666667, 23.34980392,\n",
       "       23.34980392, 32.11304348, 23.34980392, 23.34980392, 23.34980392,\n",
       "       45.09666667, 32.11304348, 45.09666667, 45.09666667, 32.11304348,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 32.11304348, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 14.956     , 23.34980392, 32.11304348,\n",
       "       23.34980392, 23.34980392, 23.34980392, 32.11304348, 32.11304348,\n",
       "       23.34980392, 32.11304348, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 14.956     , 14.956     , 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 32.11304348, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 14.956     , 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 23.34980392, 23.34980392, 14.956     , 45.09666667,\n",
       "       23.34980392, 23.34980392, 23.34980392, 23.34980392, 23.34980392,\n",
       "       32.11304348, 23.34980392, 23.34980392, 14.956     , 14.956     ,\n",
       "       32.11304348, 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       32.11304348, 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 23.34980392, 14.956     , 14.956     ,\n",
       "       23.34980392, 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 23.34980392, 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 23.34980392, 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 32.11304348, 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 23.34980392, 23.34980392, 23.34980392,\n",
       "       23.34980392, 14.956     , 14.956     , 14.956     , 14.956     ,\n",
       "       14.956     , 23.34980392, 23.34980392, 32.11304348, 14.956     ,\n",
       "       14.956     , 14.956     , 14.956     , 14.956     , 23.34980392,\n",
       "       23.34980392, 23.34980392, 32.11304348, 23.34980392, 23.34980392,\n",
       "       23.34980392, 14.956     , 23.34980392, 14.956     , 14.956     ,\n",
       "       14.956     , 14.956     , 23.34980392, 23.34980392, 23.34980392,\n",
       "       14.956     , 14.956     , 23.34980392, 23.34980392, 14.956     ,\n",
       "       23.34980392, 23.34980392, 23.34980392, 32.11304348, 23.34980392,\n",
       "       23.34980392])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = cart.predict(boston.data)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are functions provided by `sklearn.metrics` to evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5736909785051676\n",
      "25.69946745212606\n",
      "0.695574477973027\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests and Boosting\n",
    "\n",
    "Random forests and boosting for regression work the same as in classification, except we use the `Regressor` version rather than `Classifier`.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Test and compare the (in-sample) performance of random forests and boosting on the Boston data with some sensible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8015256916996039\n",
      "1.403098794466401\n",
      "0.9833794578134142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(n_estimators=100)\n",
    "forest.fit(boston.data, boston.target)\n",
    "preds = forest.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772623394132104\n",
      "0.9809578962773967\n",
      "0.9883799685648341\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "boost = GradientBoostingRegressor(n_estimators=100, learning_rate=0.2)\n",
    "boost.fit(boston.data, boston.target)\n",
    "preds = boost.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026413507235379965\n",
      "0.0014430003436840648\n",
      "0.9999829068001611\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "boost2 = XGBRegressor()\n",
    "boost2.fit(boston.data, boston.target)\n",
    "preds = boost2.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(max_iter=1000)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(max_iter=1000)\n",
    "mlp.fit(boston.data, boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.778925080695003\n",
      "15.118711213942651\n",
      "0.8209098471688843\n"
     ]
    }
   ],
   "source": [
    "preds = mlp.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 416.3250\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 189.9820\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 147.3391\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 123.4213\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 101.8594\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 86.1179\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 76.7525: 0s - loss: 74.\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 71.9598\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 68.5318\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 66.7393\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 68.3569\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 229.8424\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 152.8784\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 124.9488\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 101.3086A: 0s - loss: 103.713\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 83.7563\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 72.4537\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 68.8848\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 65.2835\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 63.0682\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 61.2580\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 78.1588\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 394.2870\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 154.2006\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 121.5101\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 96.5747\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 79.6176\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 71.7972\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 67.3771\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 65.3503\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 63.4878\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 62.6430\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 72.4628\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 457.5549\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 213.4543\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 137.6380\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123.8971\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 111.1874\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 101.2769\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 91.2895\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 84.0696\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 79.6263\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 76.9124\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 49.1916\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 337.1278\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 109.4944\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 95.3181\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 88.5550\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 83.2130\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 79.5414\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 76.1562\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 74.1669\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 73.5261\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 74.5165\n",
      "7/7 [==============================] - 0s 854us/step - loss: 74.1472\n",
      "Mean Squared Error: 68.46 (10.14)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "X = boston.data\n",
    "Y = boston.target\n",
    " \n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=X.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=10, batch_size=16, verbose=1)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Mean Squared Error: %.2f (%.2f)\" % (abs(results.mean()), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a large collection of linear regression models in sklearn. Let's start with a simple ordinary linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.270862810900317\n",
      "21.894831181729206\n",
      "0.7406426641094094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear = LinearRegression()\n",
    "linear.fit(boston.data, boston.target)\n",
    "preds = linear.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at the betas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.08011358e-01,  4.64204584e-02,  2.05586264e-02,  2.68673382e+00,\n",
       "       -1.77666112e+01,  3.80986521e+00,  6.92224640e-04, -1.47556685e+00,\n",
       "        3.06049479e-01, -1.23345939e-02, -9.52747232e-01,  9.31168327e-03,\n",
       "       -5.24758378e-01])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use regularized models as well. Here is ridge regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.315169248123664\n",
      "22.660363555639318\n",
      "0.7315744764907257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.10143535,  0.0495791 , -0.0429624 ,  1.95202082, -2.37161896,\n",
       "        3.70227207, -0.01070735, -1.24880821,  0.2795956 , -0.01399313,\n",
       "       -0.79794498,  0.01003684, -0.55936642])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=10)\n",
    "ridge.fit(boston.data, boston.target)\n",
    "preds = ridge.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6117102456478434\n",
      "26.79609915726647\n",
      "0.6825842212709925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.06343729,  0.04916467, -0.        ,  0.        , -0.        ,\n",
       "        0.9498107 ,  0.02090951, -0.66879   ,  0.26420643, -0.01521159,\n",
       "       -0.72296636,  0.00824703, -0.76111454])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(boston.data, boston.target)\n",
    "preds = lasso.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other linear regression models available. See the [linear model documentation](http://scikit-learn.org/stable/modules/linear_model.html) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "The elastic net is another linear regression method that combines ridge and lasso regularization. Try running it on this dataset, referring to the documentation as needed to learn how to use it and control the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6003900945410816\n",
      "26.61250550876538\n",
      "0.6847589975534153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.07357712,  0.05213586, -0.        ,  0.        , -0.        ,\n",
       "        0.93878931,  0.02034843, -0.72517373,  0.28929928, -0.01621831,\n",
       "       -0.73867242,  0.00831955, -0.76045672])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "elastic = ElasticNet(alpha=1, l1_ratio=.7)\n",
    "elastic.fit(boston.data, boston.target)\n",
    "preds = elastic.predict(boston.data)\n",
    "print(mean_absolute_error(boston.target, preds))\n",
    "print(mean_squared_error(boston.target, preds))\n",
    "print(r2_score(boston.target, preds))\n",
    "elastic.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "?DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
