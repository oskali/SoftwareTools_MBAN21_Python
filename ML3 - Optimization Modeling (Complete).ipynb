{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization in Python\n",
    "\n",
    "You might have noticed that we didn't do anything related to sparsity with scikit-learn models. A lot of the work we covered in the machine learning class is very recent research, and as such is typically not implemented by the popular libraries.\n",
    "\n",
    "If we want to do things like sparse regression, we're going to have to roll up our sleeves and do it ourselves. For that, we need to be able to solve optimization problems. In Julia, we did this with JuMP. In Python, we'll use a similar library called *pyomo*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing pyomo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the following command to install pyomo if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pyomo --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to pyomo\n",
    "\n",
    "Let's see how we translate a simple, 2 variable LP to pyomo code.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\max_{x,y} \\quad& x + 2y \\\\\n",
    "\\text{s.t.}\\quad& x + y \\leq 1 \\\\\n",
    "& x, y \\geq 0.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing is to import the pyomo functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyomo.environ import *\n",
    "from pyomo.opt import SolverFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we construct a model object. This is a container for everything in our optimization problem: variables, constraints, solver options, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ConcreteModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the two decision variables in our optimization problem. We use the ``Var`` function to create the variables. The `within` keyword is used to specify the bounds on the variables, or equivalently the `bounds` keyword. The variables are added to the model object with names `x` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.x = Var(within=NonNegativeReals)\n",
    "m.y = Var(bounds=(0, float('inf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add the single constraint of our problem using the ``Constraint`` function. We write it algebraically, and save the result to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.con = Constraint(expr=m.x + m.y <= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the objective function with the `Objective` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.obj = Objective(sense=maximize, expr=m.x + 2 * m.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve the optimization problem by first specifying a solver using `SolverFactory` and then using this solver to solve the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Problem': [{'Name': 'x3', 'Lower bound': 2.0, 'Upper bound': 2.0, 'Number of objectives': 1, 'Number of constraints': 2, 'Number of variables': 3, 'Number of binary variables': 0, 'Number of integer variables': 0, 'Number of continuous variables': 3, 'Number of nonzeros': 3, 'Sense': 'maximize'}], 'Solver': [{'Status': 'ok', 'Return code': '0', 'Message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Termination condition': 'optimal', 'Termination message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Wall time': '0.06682205200195312', 'Error rc': 0, 'Time': 1.0039210319519043}], 'Solution': [OrderedDict([('number of solutions', 0), ('number of solutions displayed', 0)])]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = SolverFactory('gurobi')\n",
    "solver.solve(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the solution values and optimal cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.y.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all together to compare with Julia/JuMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "m = ConcreteModel()\n",
    "# Add variables\n",
    "m.x = Var(within=NonNegativeReals)\n",
    "m.y = Var(bounds=(0, float('inf')))\n",
    "# Add constraint\n",
    "m.con = Constraint(expr=m.x + m.y <= 1)\n",
    "# Add objective\n",
    "m.obj = Objective(sense=maximize, expr=m.x + 2 * m.y)\n",
    "# Solve model\n",
    "solver = SolverFactory('gurobi')\n",
    "solver.solve(m)\n",
    "# Inspect solution\n",
    "print(m.obj())\n",
    "print(m.x.value)\n",
    "print(m.y.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "# Create model\n",
    "m = Model(solver=GurobiSolver())\n",
    "# Add variables\n",
    "@variable(m, x >= 0)\n",
    "@variable(m, y >= 0)\n",
    "# Add constraint\n",
    "@constraint(m, x + y <= 1)\n",
    "# Add objective\n",
    "@objective(m, Max, x + 2y)\n",
    "# Solve model\n",
    "solve(m)\n",
    "# Inspect solution\n",
    "@show getobjectivevalue(m)\n",
    "@show getvalue(x)\n",
    "@show getvalue(y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Code and solve the following optimization problem:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\min_{x,y} \\quad& 3x - y \\\\\n",
    "\\text{s.t.}\\quad& x + 2y \\geq 1 \\\\\n",
    "& x \\geq 0 \\\\\n",
    "& 0 \\leq y \\leq 1.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "m = ConcreteModel()\n",
    "# Add the variables\n",
    "m.x = Var(within=NonNegativeReals)\n",
    "m.y = Var(bounds=(0, 1))\n",
    "# Add the constraint\n",
    "m.con = Constraint(expr=m.x + 2 * m.y >= 1)\n",
    "# Add the objective\n",
    "m.obj = Objective(sense=minimize, expr=3 * m.x - m.y)\n",
    "\n",
    "solver = SolverFactory('gurobi')\n",
    "solver.solve(m)\n",
    "\n",
    "print(m.x.value, m.y.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 0.0\n",
      "y 1.0\n"
     ]
    }
   ],
   "source": [
    "for v in m.component_data_objects(Var, active=True):\n",
    "    print(v, value(v)) # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Var Declarations\n",
      "    x : Size=1, Index=None\n",
      "        Key  : Lower : Value : Upper : Fixed : Stale : Domain\n",
      "        None :     0 :   0.0 :  None : False : False : NonNegativeReals\n",
      "    y : Size=1, Index=None\n",
      "        Key  : Lower : Value : Upper : Fixed : Stale : Domain\n",
      "        None :     0 :   1.0 :     1 : False : False :  Reals\n",
      "\n",
      "1 Objective Declarations\n",
      "    obj : Size=1, Index=None, Active=True\n",
      "        Key  : Active : Sense    : Expression\n",
      "        None :   True : minimize : 3*x - y\n",
      "\n",
      "1 Constraint Declarations\n",
      "    con : Size=1, Index=None, Active=True\n",
      "        Key  : Lower : Body    : Upper : Active\n",
      "        None :   1.0 : x + 2*y :  +Inf :   True\n",
      "\n",
      "4 Declarations: x y con obj\n"
     ]
    }
   ],
   "source": [
    "m.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index sets\n",
    "\n",
    "Let's now move to a more complicated problem. We'll look at a transportation problem:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min & \\sum\\limits_{i = 1}^{m} \\sum\\limits_{j = 1}^{n} c_{ij} x_{ij}\\\\\n",
    "& \\sum\\limits_{j = 1}^{n} x_{ij} \\leq b_i && i = 1, \\ldots, m\\\\\n",
    "& \\sum\\limits_{i = 1}^{m} x_{ij} = d_j && j = 1, \\ldots, n\\\\\n",
    "& x_{ij} \\ge 0 && i = 1, \\ldots, m, j = 1, \\ldots, n\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And with some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "m = 2  # Number of supply nodes\n",
    "n = 5  # Number of demand nodes\n",
    "# Supplies\n",
    "b = np.array([1000, 4000])\n",
    "# Demands\n",
    "d = np.array([500, 900, 1800, 200, 700])\n",
    "# Costs\n",
    "c = np.array([[2, 4, 5, 2, 1], \n",
    "              [3, 1, 3, 2, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can formulate the problem with pyomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConcreteModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is adding variables. We can add variables with indices by passing the relevant index sets to the `Var` constructor. In this case, we need a $m$-by$n$ matrix of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.x = Var(range(m), range(n), within=NonNegativeReals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to add the constraints. We have to add one supply constraint for each factory, so we might try something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Implicitly replacing the Component attribute supply (type=<class\n",
      "    'pyomo.core.base.constraint.SimpleConstraint'>) on block unknown with a\n",
      "    new Component (type=<class\n",
      "    'pyomo.core.base.constraint.SimpleConstraint'>). This is usually\n",
      "    indicative of a modelling error. To avoid this warning, use\n",
      "    block.del_component() and block.add_component().\n"
     ]
    }
   ],
   "source": [
    "for i in range(m):\n",
    "    model.supply = Constraint(expr=sum(model.x[i, j] for j in range(n)) <= b[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see the problem? We are overwriting `model.supply` in each iteration of the loop, and so only the last constraint is applied.\n",
    "\n",
    "Luckily, pyomo has a (not-so-easy) way to add multiple constraints at a time. We first define a *rule* that takes in the model and any required indices, and then returns the expression for the constraint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supply_rule(model, i):\n",
    "    return sum(model.x[i, j] for j in range(n)) <= b[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add the constraint by referencing this rule along with the index set we want the constraint to be defined over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.supply2 = Constraint(range(m), rule=supply_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply the same approach for the demand constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand_rule(model, j):\n",
    "    return sum(model.x[i, j] for i in range(m)) == d[j]\n",
    "\n",
    "model.demand = Constraint(range(n), rule=demand_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add the objective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.obj = Objective(sense=minimize, \n",
    "    expr=sum(c[i, j] * model.x[i, j] \n",
    "    for i in range(m) for j in range(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can solve the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Problem': [{'Name': 'x11', 'Lower bound': 8600.0, 'Upper bound': 8600.0, 'Number of objectives': 1, 'Number of constraints': 9, 'Number of variables': 11, 'Number of binary variables': 0, 'Number of integer variables': 0, 'Number of continuous variables': 11, 'Number of nonzeros': 26, 'Sense': 'minimize'}], 'Solver': [{'Status': 'ok', 'Return code': '0', 'Message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Termination condition': 'optimal', 'Termination message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Wall time': '0.04288291931152344', 'Error rc': 0, 'Time': 0.31615591049194336}], 'Solution': [OrderedDict([('number of solutions', 0), ('number of solutions displayed', 0)])]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = SolverFactory('gurobi')\n",
    "solver.solve(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It solved, so we can extract the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 300.,    0.,    0.,    0.,  700.],\n",
       "       [ 200.,  900., 1800.,  200.,    0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flows = np.array([[model.x[i, j].value for j in range(n)] for i in range(m)])\n",
    "flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the objective value for the cost of this flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8600.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, here is the entire formulation and solving code together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConcreteModel()\n",
    "# Variables\n",
    "model.x = Var(range(m), range(n), within=NonNegativeReals)\n",
    "# Supply constraint\n",
    "def supply_rule(model, i):\n",
    "    return sum(model.x[i, j] for j in range(n)) <= b[i]\n",
    "model.supply2 = Constraint(range(m), rule=supply_rule)\n",
    "# Demand constraint\n",
    "def demand_rule(model, j):\n",
    "    return sum(model.x[i, j] for i in range(m)) == d[j]\n",
    "model.demand = Constraint(range(n), rule=demand_rule)\n",
    "# Objective\n",
    "model.obj = Objective(sense=minimize, \n",
    "    expr=sum(c[i, j] * model.x[i, j] \n",
    "    for i in range(m) for j in range(n)))\n",
    "# Solve\n",
    "solver = SolverFactory('gurobi')\n",
    "solver.solve(model)\n",
    "# Get results\n",
    "flows = np.array([[model.x[i, j].value for j in range(n)] for i in range(m)])\n",
    "model.obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Now let's put our pyomo knowledge to use and implement some of the same methods we saw in the machine learning class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, specify your solver executable location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable='C:/Users/omars/.julia/v0.6/Ipopt/deps/usr/bin/ipopt.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the version left over from Julia\n",
    "### On MacOS and Linux\n",
    "\n",
    "`executable=\"~/.julia/v0.6/Homebrew/deps/usr/Cellar/ipopt/3.12.4_1/bin/ipopt\")`\n",
    "\n",
    "### On Windows\n",
    "\n",
    "The path is probably under WinRPM:\n",
    "\n",
    "`executable='%HOME%/.julia/v0.6/WinRPM/...')\")`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Let's just try a simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y):\n",
    "    n, p = X.shape\n",
    "\n",
    "    # Create model\n",
    "    m = ConcreteModel()\n",
    "\n",
    "    # Add variables\n",
    "    m.beta = Var(range(p))\n",
    "\n",
    "    # Add constraints\n",
    "\n",
    "    # Add objective\n",
    "    m.obj = Objective(sense=minimize, expr=sum(\n",
    "        pow(y[i] - sum(X[i, j] * m.beta[j] for j in range(p)), 2) \n",
    "        for i in range(n)))\n",
    "\n",
    "    solver = SolverFactory('ipopt', executable=executable)\n",
    "    \n",
    "    ## tee=True enables solver output\n",
    "    # results = solver.solve(m, tee=True)\n",
    "    results = solver.solve(m, tee=False)\n",
    "\n",
    "    return [m.beta[j].value for j in range(p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load up some data to test it out on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try our linear regression function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0928965170276332, 0.04871495518299193, -0.004059979574994615, 2.8539988199938313, -2.8684363704210067, 5.928147779053185, -0.007269334576040927, -0.9685141573949657, 0.1711511282943897, -0.009396215397156512, -0.39219092629505153, 0.014905610228206412, -0.4163044707374162]\n"
     ]
    }
   ],
   "source": [
    "print(linear_regression(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare with sklearn to make sure it's right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.28965170e-02,  4.87149552e-02, -4.05997958e-03,  2.85399882e+00,\n",
       "       -2.86843637e+00,  5.92814778e+00, -7.26933458e-03, -9.68514157e-01,\n",
       "        1.71151128e-01, -9.39621540e-03, -3.92190926e-01,  1.49056102e-02,\n",
       "       -4.16304471e-01])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "m = LinearRegression(fit_intercept=False)\n",
    "m.fit(X, y)\n",
    "m.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for reference, let's look back at how we do the same thing in JuMP!\n",
    "\n",
    "```julia\n",
    "using JuMP, Gurobi\n",
    "function linear_regression(X, y)\n",
    "    n, p = size(X)\n",
    "    m = Model(solver=GurobiSolver())\n",
    "    @variable(m, beta[1:p])\n",
    "    @objective(m, Min, sum((y[i] - sum(X[i, j] * beta[j] for j = 1:p)) ^ 2 for i = 1:n))\n",
    "    solve(m)\n",
    "    getvalue(beta)\n",
    "end\n",
    "```\n",
    "\n",
    "or even\n",
    "\n",
    "```julia\n",
    "using JuMP, Gurobi\n",
    "function linear_regression(X, y)\n",
    "    n, p = size(X)\n",
    "    m = Model(solver=GurobiSolver())\n",
    "    @variable(m, beta[1:p])\n",
    "    @objective(m, Min, sum((y - X * beta) .^ 2))\n",
    "    solve(m)\n",
    "    getvalue(beta)\n",
    "end\n",
    "```\n",
    "\n",
    "Much simpler!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Modify the linear regression formulation to include an intercept term, and compare to scikit-learn's LinearRegression with `fit_intercept=False` to make sure it's the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.10801135783681295,\n",
       " 0.046420458366832826,\n",
       " 0.020558626367267345,\n",
       " 2.6867338193441053,\n",
       " -17.766611228344583,\n",
       " 3.8098652068064345,\n",
       " 0.0006922246403880231,\n",
       " -1.4755668456006032,\n",
       " 0.30604947898554247,\n",
       " -0.012334593916578101,\n",
       " -0.9527472317092022,\n",
       " 0.009311683273791104,\n",
       " -0.5247583778555439]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_regression_intercept(X, y):\n",
    "    n, p = X.shape\n",
    "\n",
    "    # Create model\n",
    "    m = ConcreteModel()\n",
    "\n",
    "    # Add variables\n",
    "    m.beta = Var(range(p))\n",
    "    m.b0 = Var()\n",
    "\n",
    "    # Add constraints\n",
    "\n",
    "    # Add objective\n",
    "    m.obj = Objective(sense=minimize, expr=sum(\n",
    "        pow(y[i] - sum(X[i, j] * m.beta[j] for j in range(p)) - m.b0, 2) \n",
    "        for i in range(n)))\n",
    "\n",
    "    solver = SolverFactory('ipopt', executable=executable)\n",
    "    \n",
    "    ## tee=True enables solver output\n",
    "    # results = solver.solve(m, tee=True)\n",
    "    results = solver.solve(m, tee=False)\n",
    "\n",
    "    return [m.beta[j].value for j in range(p)]\n",
    "\n",
    "linear_regression_intercept(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.08011358e-01,  4.64204584e-02,  2.05586264e-02,  2.68673382e+00,\n",
       "       -1.77666112e+01,  3.80986521e+00,  6.92224640e-04, -1.47556685e+00,\n",
       "        3.06049479e-01, -1.23345939e-02, -9.52747232e-01,  9.31168327e-03,\n",
       "       -5.24758378e-01])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LinearRegression(fit_intercept=True)\n",
    "m.fit(X, y)\n",
    "m.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Regression\n",
    "\n",
    "We saw in the class that both ridge and lasso regression were robust versions of linear regression. Both of these are provided by `sklearn`, but we need to know how to implement them if we want to extend regression ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X, y, rho):\n",
    "    n, p = X.shape\n",
    "\n",
    "    # Create model\n",
    "    m = ConcreteModel()\n",
    "\n",
    "    # Add variables\n",
    "    m.beta = Var(range(p))\n",
    "\n",
    "    # Add objective\n",
    "    m.obj = Objective(sense=minimize, expr=sum(\n",
    "        pow(y[i] - sum(X[i, j] * m.beta[j] for j in range(p)),2) \n",
    "        for i in range(n)) + rho * sum(pow(m.beta[j], 2) for j in range(p)))\n",
    "\n",
    "    solver = SolverFactory('ipopt', executable=executable)\n",
    "    \n",
    "    ## tee=True enables solver output\n",
    "    # results = solver.solve(m, tee=True)\n",
    "    results = solver.solve(m, tee=False)\n",
    "    return [m.beta[j].value for j in range(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03349704413300387,\n",
       " 0.09109374003810565,\n",
       " -0.020781437073126584,\n",
       " 0.001953623650442121,\n",
       " 0.0010799179606038737,\n",
       " 0.036595936096463166,\n",
       " 0.031147076775253392,\n",
       " 0.008145310191304656,\n",
       " 0.000355681037898492,\n",
       " 0.0012341682146102984,\n",
       " 0.025195318040087757,\n",
       " 0.05360061512165024,\n",
       " -0.09887567363356603]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regression(X, y, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso(X, y, rho):\n",
    "    n, p = X.shape\n",
    "\n",
    "    # Create model\n",
    "    m = ConcreteModel()\n",
    "\n",
    "    # Add variables\n",
    "    m.beta = Var(range(p))\n",
    "\n",
    "    # Add objective\n",
    "    m.obj = Objective(sense=minimize, expr=sum(\n",
    "        pow(y[i] - sum(X[i, j] * m.beta[j] for j in range(p)),2) \n",
    "        for i in range(n)) + rho * sum(pow(m.beta[j], 2) for j in range(p)))\n",
    "\n",
    "    solver = SolverFactory('ipopt', executable=executable)\n",
    "    \n",
    "    ## tee=True enables solver output\n",
    "    # results = solver.solve(m, tee=True)\n",
    "    results = solver.solve(m, tee=False)\n",
    "    return [m.beta[j].value for j in range(p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Implement Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regression(X, y, rho):\n",
    "    n, p = X.shape\n",
    "\n",
    "    # Create model\n",
    "    m = ConcreteModel()\n",
    "\n",
    "    # Add variables\n",
    "    m.beta = Var(range(p))\n",
    "    m.absb = Var(range(p))\n",
    "\n",
    "    # Add constraints\n",
    "    def absbeta1(m, j):\n",
    "        return m.beta[j] <= m.absb[j]\n",
    "    m.absb1 = Constraint(range(p), rule=absbeta1)\n",
    "    def absbeta2(m, j):\n",
    "        return -m.beta[j] <= m.absb[j]\n",
    "    m.absb2 = Constraint(range(p), rule=absbeta2)\n",
    "        \n",
    "\n",
    "    # Add objective\n",
    "    m.obj = Objective(sense=minimize, expr=sum(\n",
    "        pow(y[i] - sum(X[i, j] * m.beta[j] for j in range(p)), 2) \n",
    "        for i in range(n)) + rho * sum(m.absb[j] for j in range(p)))\n",
    "\n",
    "    solver = SolverFactory('ipopt', executable=executable)\n",
    "    \n",
    "    ## tee=True enables solver output\n",
    "    # results = solver.solve(m, tee=True)\n",
    "    results = solver.solve(m, tee=False)\n",
    "    return [m.beta[j].value for j in range(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_regression(X, y, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_regression(X, y, k):\n",
    "    n, p = X.shape\n",
    "    M = 1000\n",
    "\n",
    "    # Create model\n",
    "    m = ConcreteModel()\n",
    "\n",
    "    # Add variables\n",
    "    m.beta = Var(range(p))\n",
    "    m.z = Var(range(p), within=Binary)\n",
    "\n",
    "    # Add constraints\n",
    "    def bigm1(m, j):\n",
    "        return m.beta[j] <= M * m.z[j]\n",
    "    m.bigm1 = Constraint(range(p), rule=bigm1)\n",
    "    def bigm2(m, j):\n",
    "        return m.beta[j] >= -M * m.z[j]\n",
    "    m.bigm2 = Constraint(range(p), rule=bigm2)\n",
    "        \n",
    "    m.sparsity = Constraint(expr=sum(m.z[j] for j in range(p)) <= k)\n",
    "\n",
    "    # Add objective\n",
    "    m.obj = Objective(sense=minimize, expr=sum(\n",
    "        pow(y[i] - sum(X[i, j] * m.beta[j] for j in range(p)), 2) \n",
    "        for i in range(n)))\n",
    "\n",
    "    solver = SolverFactory('ipopt', executable=executable)\n",
    "    \n",
    "    ## tee=True enables solver output\n",
    "    # results = solver.solve(m, tee=True)\n",
    "    results = solver.solve(m, tee=False)\n",
    "    return [m.beta[j].value for j in range(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.09289651702716464,\n",
       " 0.048714955183037804,\n",
       " -0.004059979575834942,\n",
       " 2.8539988201207356,\n",
       " -2.868436370310866,\n",
       " 5.9281477790418435,\n",
       " -0.0072693345761560306,\n",
       " -0.9685141573945727,\n",
       " 0.1711511282944914,\n",
       " -0.009396215397248317,\n",
       " -0.39219092628560964,\n",
       " 0.014905610227998044,\n",
       " -0.4163044707410663]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_regression(X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  4  9 16]\n",
      "[1.0, 1.4142135623730951, 1.7320508075688772, 2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "l = np.array([1,2,3,4])\n",
    "\n",
    "print(l**2)\n",
    "print([sqrt(i) for i in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try implementing the algorithmic framework for linear regression:\n",
    "- sparsity constraints\n",
    "- lasso regularization\n",
    "- restrict highly correlated pairs of features\n",
    "- nonlinear transformations (just $\\sqrt(x)$ and $x^2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def all_regression(X_orig, y, k, rho):\n",
    "    n, p_orig = X_orig.shape\n",
    "    M = 10\n",
    "    \n",
    "    X = np.concatenate(\n",
    "        [X_orig, np.sqrt(X_orig), np.square(X_orig)], axis=1\n",
    "    )\n",
    "    p = X.shape[1]\n",
    "    \n",
    "    # Normalize data\n",
    "    X = normalize(X, axis=0)\n",
    "    y = (y - np.mean(y)) / np.linalg.norm(y)\n",
    "\n",
    "    # Create model\n",
    "    m = ConcreteModel()\n",
    "\n",
    "    # Add variables\n",
    "    m.beta = Var(range(p))\n",
    "    m.z = Var(range(p), within=Binary)\n",
    "    m.absb = Var(range(p))\n",
    "\n",
    "    # Sparsity constraints\n",
    "    def bigm1(m, j):\n",
    "        return m.beta[j] <= M * m.z[j]\n",
    "    m.bigm1 = Constraint(range(p), rule=bigm1)\n",
    "    def bigm2(m, j):\n",
    "        return m.beta[j] >= -M * m.z[j]\n",
    "    m.bigm2 = Constraint(range(p), rule=bigm2)\n",
    "    m.sparsity = Constraint(expr=sum(m.z[j] for j in range(p)) <= k)\n",
    "    \n",
    "    # Lasso constraints\n",
    "    def absbeta1(m, j):\n",
    "        return m.beta[j] <= m.absb[j]\n",
    "    m.absb1 = Constraint(range(p), rule=absbeta1)\n",
    "    def absbeta2(m, j):\n",
    "        return -m.beta[j] <= m.absb[j]\n",
    "    m.absb2 = Constraint(range(p), rule=absbeta2)\n",
    "    \n",
    "    # Correlation constraints\n",
    "    corX = np.corrcoef(np.transpose(X))\n",
    "    def cor_rule(m, i, j):\n",
    "        if i > j and abs(corX[i, j]) > 0.8:\n",
    "            return (sum(m.z[k] for k in range(i, p, p_orig)) + \n",
    "                    sum(m.z[k] for k in range(j, p, p_orig)) <= 1)\n",
    "        else:\n",
    "            return Constraint.Skip\n",
    "    m.cor = Constraint(range(p_orig), range(p_orig), rule=cor_rule)\n",
    "    \n",
    "    # Nonlinear constraints\n",
    "    def nl_rule(m, i):\n",
    "        return sum(m.z[k] for k in range(i, p, p_orig)) <= 1\n",
    "    m.nl = Constraint(range(p_orig), rule=nl_rule)\n",
    "\n",
    "    # Add objective\n",
    "    m.obj = Objective(sense=minimize, expr=sum(\n",
    "        pow(y[i] - sum(X[i, j] * m.beta[j] for j in range(p)), 2) \n",
    "        for i in range(n)) + rho * sum(m.absb[j] for j in range(p)))\n",
    "\n",
    "    solver = SolverFactory('ipopt', executable=executable)\n",
    "    \n",
    "    ## tee=True enables solver output\n",
    "#     results = solver.solve(m, tee=True)\n",
    "    results = solver.solve(m, tee=False)\n",
    "\n",
    "    return np.array([m.beta[j].value for j in range(p)]).reshape(-1, p_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2436117 , -0.40635426,  1.287454  ,  0.00847825, -3.77070371,\n",
       "        -5.52116145, -0.89579769,  1.8866262 , -1.2658388 , -0.27200984,\n",
       "        -4.29661229,  1.08490846,  0.87517741],\n",
       "       [ 0.08922823,  0.22757203, -1.40483302,  0.00847825,  6.06383002,\n",
       "         1.71571313,  0.89614225, -3.03336942,  1.22670959, -0.27220395,\n",
       "         5.06365681, -0.5261114 , -1.95285925],\n",
       "       [ 0.1005534 ,  0.19449394, -0.33587296,  0.00847825,  0.1653508 ,\n",
       "         2.76298931,  0.2188393 , -0.32862084,  0.51518994,  0.15346198,\n",
       "         0.63958091, -0.5226175 , -0.10282404]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_regression(X, y, 6, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like JuMP, we need to use a new solver for the nonlinear problem. We can use Ipopt as before, except we have to set it up manually. You'll need to download Ipopt and add it to the PATH. \n",
    "\n",
    "On Mac, you can do this with Homebrew if you have it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way is to download a copy of ipopt and specify the path to it exactly when creating the solver. For example, I have a copy of Ipopt left over from JuMP, which I can use by modifying the SolverFactory line as indicated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y):\n",
    "    n, p = X.shape\n",
    "    \n",
    "    # Convert y to (-1, +1)\n",
    "    assert np.min(y) == 0\n",
    "    assert np.max(y) == 1\n",
    "    Y = y * 2 - 1\n",
    "    assert np.min(Y) == -1\n",
    "    assert np.max(Y) == 1\n",
    "\n",
    "    # Create the model\n",
    "    m = ConcreteModel()\n",
    "\n",
    "    # Add variables\n",
    "    m.b = Var(range(p))\n",
    "    m.b0 = Var()\n",
    "\n",
    "    # Set nonlinear objective function\n",
    "    m.obj = Objective(sense=maximize, expr=-sum(\n",
    "        log(1 + exp(-Y[i] * (sum(X[i, j] * m.b[j] for j in range(p)) + m.b0)))\n",
    "        for i in range(n)))\n",
    "\n",
    "    # Solve the model and get the optimal solutions\n",
    "    solver = SolverFactory('ipopt', executable=executable)\n",
    "        \n",
    "    solver.solve(m)\n",
    "    return [m.b[j].value for j in range(p)], m.b0.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4149.289184609701,\n",
       "  -95.66597524418847,\n",
       "  -122.72220946545622,\n",
       "  -31.07342010773767,\n",
       "  -30864.886098201634,\n",
       "  36295.57939884905,\n",
       "  -19052.20895802693,\n",
       "  -19686.209843004974,\n",
       "  14077.278909141973,\n",
       "  -45229.07643132272,\n",
       "  -2194.6637679242845,\n",
       "  98.59470071343296,\n",
       "  810.8129671962596,\n",
       "  -71.48231452267014,\n",
       "  65260.80657288916,\n",
       "  -62374.925075090185,\n",
       "  52121.749598051225,\n",
       "  -203728.7743634409,\n",
       "  62535.47114299024,\n",
       "  488515.76125488814,\n",
       "  -1086.5758594687723,\n",
       "  -31.442744168114533,\n",
       "  -43.120968967631356,\n",
       "  7.303064300605229,\n",
       "  3500.09658663806,\n",
       "  5108.10478323704,\n",
       "  -4412.61061910415,\n",
       "  -4740.534608043277,\n",
       "  -14164.859267037991,\n",
       "  -35109.19922500868],\n",
       " -323.2327374749216)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Implement the regularized versions of logistic regression that scikit-learn provides:\n",
    "\n",
    "![](http://scikit-learn.org/stable/_images/math/6a0bcf21baaeb0c2b879ab74fe333c0aab0d6ae6.png)\n",
    "\n",
    "![](http://scikit-learn.org/stable/_images/math/760c999ccbc78b72d2a91186ba55ce37f0d2cf37.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_l1(X, y, C):\n",
    "    n, p = X.shape\n",
    "    \n",
    "    # Convert y to (-1, +1)\n",
    "    assert np.min(y) == 0\n",
    "    assert np.max(y) == 1\n",
    "    Y = y * 2 - 1\n",
    "    assert np.min(Y) == -1\n",
    "    assert np.max(Y) == 1\n",
    "\n",
    "    # Create the model\n",
    "    m = ConcreteModel()\n",
    "\n",
    "    # Add variables\n",
    "    m.b = Var(range(p))\n",
    "    m.b0 = Var()\n",
    "    \n",
    "    # Lasso constraints\n",
    "    m.absb = Var(range(p))\n",
    "    def absbeta1(m, j):\n",
    "        return m.b[j] <= m.absb[j]\n",
    "    m.absb1 = Constraint(range(p), rule=absbeta1)\n",
    "    def absbeta2(m, j):\n",
    "        return -m.b[j] <= m.absb[j]\n",
    "    m.absb2 = Constraint(range(p), rule=absbeta2)\n",
    "    \n",
    "    # Set nonlinear objective function\n",
    "    m.obj = Objective(sense=minimize, expr=sum(m.absb[j] for j in range(p)) + C * sum(\n",
    "        log(1 + exp(-Y[i] * (sum(X[i, j] * m.b[j] for j in range(p)) + m.b0)))\n",
    "        for i in range(n)))\n",
    "\n",
    "    # Solve the model and get the optimal solutions\n",
    "    solver = SolverFactory('ipopt', executable=executable)\n",
    "    \n",
    "    solver.solve(m)\n",
    "    return [m.b[j].value for j in range(p)], m.b0.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_l1(X, y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_l2(X, y, C):\n",
    "    n, p = X.shape\n",
    "    \n",
    "    # Convert y to (-1, +1)\n",
    "    assert np.min(y) == 0\n",
    "    assert np.max(y) == 1\n",
    "    Y = y * 2 - 1\n",
    "    assert np.min(Y) == -1\n",
    "    assert np.max(Y) == 1\n",
    "\n",
    "    # Create the model\n",
    "    m = ConcreteModel()\n",
    "\n",
    "    # Add variables\n",
    "    m.b = Var(range(p))\n",
    "    m.b0 = Var()\n",
    "    \n",
    "    # Set nonlinear objective function\n",
    "    m.obj = Objective(sense=minimize, expr=0.5 * sum(pow(m.b[j], 2) for j in range(p)) + C * sum(\n",
    "        log(1 + exp(-Y[i] * (sum(X[i, j] * m.b[j] for j in range(p)) + m.b0)))\n",
    "        for i in range(n)))\n",
    "\n",
    "    # Solve the model and get the optimal solutions\n",
    "    solver = SolverFactory('ipopt', executable=executable)\n",
    "    \n",
    "    solver.solve(m)\n",
    "    return [m.b[j].value for j in range(p)], m.b0.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_l2(X, y, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
